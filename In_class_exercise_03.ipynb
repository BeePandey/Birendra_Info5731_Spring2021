{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeePandey/Birendra_Info5731_Spring2021/blob/main/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STRCh0mQqQUI"
      },
      "source": [
        "## The third In-class-exercise (9/16/2020, 20 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-v1Nff3qQUL"
      },
      "source": [
        "The purpose of this exercise is to under users' information needs, then collect the data for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvCPpiTPqQUM"
      },
      "source": [
        "Question 1 (8 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgh-ZWh0qQUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "baa18625-cc3b-46c9-f0d6-d5afdc448814"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''Research Questions: How many players are there currently in NFL and who appear first based on their roster name?Data required for this research is to browse the nfl.com website and and see the players who are in the roster currently.We can use the data to see players by alphabet and how much they represent in the NFL. What are the chances of players to be select in NFL Depending on their name.\n",
        "\n",
        "\n",
        "Steps for Collecting and Saving Data:\n",
        "I have used the BeautifulSoup library to extract the information from the website.I have extracted the name of the players by using the classname and then appended to the empty array.To extract 500 players and  I have itearted 5 times times as each page contains 100 players.Used import re remove all the blank spaces and extra spaces that showed up. I read the HTML from the URL and pass on to BeautifulSoup. Then we have to request the URL by using request. \n",
        "Get(url) and we parse the data from website.'''"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Research Questions: How many players are there currently in NFL and who appear first based on their roster name?Data required for this research is to browse the nfl.com website and and see the players who are in the roster currently.We can use the data to see players by alphabet and how much they represent in the NFL. What are the chances of players to be select in NFL Depending on their name.\\n\\n\\nSteps for Collecting and Saving Data:\\nI have used the BeautifulSoup library to extract the information from the website.I have extracted the name of the players by using the classname and then appended to the empty array.To extract 500 players and  I have itearted 5 times times as each page contains 100 players.Used import re remove all the blank spaces and extra spaces that showed up. I read the HTML from the URL and pass on to BeautifulSoup. Then we have to request the URL by using request. \\nGet(url) and we parse the data from website.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XinZrYjGqQUO"
      },
      "source": [
        "Question 2 (12 points): Write python code to collect 500 items of the data you plan to collect above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVt40tyCqQUO",
        "outputId": "e7007135-0d5e-4de3-f5de-aee0042967de"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request \n",
        "from bs4 import BeautifulSoup \n",
        "import re\n",
        "\n",
        "wiki='https://www.nfl.com/players/active/a'   # url for website \n",
        "page=urllib.request.urlopen(wiki)   #command to open the url \n",
        "\n",
        "soup=BeautifulSoup(page)  #using the soup library for webscrapping\n",
        "right_table=soup.findAll(class_=\"d3-o-player-fullname nfl-o-cta--link\")   #using the class name from the url\n",
        "is_Nflplayers=[]  #array to store the players\n",
        "for is_roster in range(5):  #Range we are pulling the information of 500 players approximately\n",
        "  for is_rosterb in right_table:   #iterating through the list \n",
        "    player=is_rosterb.text\n",
        "    is_playerc=re.compile(r'[\\n]')  #removing the extra text from  html extract \n",
        "    player=is_playerc.sub(' ',player)\n",
        "    player=player.strip()   #remove character from beginning and end \n",
        "    is_Nflplayers.append(player)  #appedning to empty array\n",
        "  \n",
        "\n",
        "is_table=pd.DataFrame(is_Nflplayers,columns=['Playername'])  #creating dataframe \n",
        "print(is_table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Playername\n",
            "0         Chidobe Awuzie\n",
            "1             Josh Avery\n",
            "2           Genard Avery\n",
            "3        Anthony Averett\n",
            "4              Lee Autry\n",
            "..                   ...\n",
            "495         Jordan Akins\n",
            "496  Freedom Akinmoladun\n",
            "497            Cam Akers\n",
            "498        Solomon Ajayi\n",
            "499        Brandon Aiyuk\n",
            "\n",
            "[500 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}