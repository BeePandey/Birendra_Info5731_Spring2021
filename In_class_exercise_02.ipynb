{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeePandey/Birendra_Info5731_Spring2021/blob/main/In_class_exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo5bsEh2eeWi"
      },
      "source": [
        "# **The second In-class-exercise (1/27/2021, 20 points in total)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sPQ58dIeqgp"
      },
      "source": [
        "(1) Write a Python program to find the duplicate elements in a given array of integers. Return -1 If there are no such elements. (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnrvKMFTeoJR",
        "outputId": "57954c91-1e12-4b1a-832e-a10283e51434"
      },
      "source": [
        "# write your answer here\n",
        "def is_duplicate(array_nums):\n",
        "    num_array = set()\n",
        "    no_duplicate = -1\n",
        "\n",
        "    for i in range(len(array_nums)):\n",
        "\n",
        "        if array_nums[i] in num_array:\n",
        "            return array_nums[i]\n",
        "        else:\n",
        "            num_array.add(array_nums[i])\n",
        "\n",
        "    return no_duplicate\n",
        "\n",
        "print(is_duplicate([5, 6, 7, 7, 4, 5]))\n",
        "print(is_duplicate([7, 5, 6, 2]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrH6n6IhZoQ"
      },
      "source": [
        "(2) Write a Python program to select all the Sundays of a specified year. (4 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSfPLd23eLpX",
        "outputId": "02bc5e42-6475-4778-8cf0-6a5ad5e76fa1"
      },
      "source": [
        "# write your answer here\n",
        "\n",
        "from datetime import date\n",
        "import calendar\n",
        "Year= 2021\n",
        "S=calendar.TextCalendar(calendar.SUNDAY)\n",
        "for f in range(1,13):\n",
        "    for i in S.itermonthdays(Year,f):\n",
        "        if i!=0:\n",
        "            day=date(Year,f,i)\n",
        "            if day.weekday()==6:\n",
        "                print(\"%s,%d-%d-%d\" % (calendar.day_name[6] ,i,f,Year))\n",
        "\n"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sunday,3-1-2021\n",
            "Sunday,10-1-2021\n",
            "Sunday,17-1-2021\n",
            "Sunday,24-1-2021\n",
            "Sunday,31-1-2021\n",
            "Sunday,7-2-2021\n",
            "Sunday,14-2-2021\n",
            "Sunday,21-2-2021\n",
            "Sunday,28-2-2021\n",
            "Sunday,7-3-2021\n",
            "Sunday,14-3-2021\n",
            "Sunday,21-3-2021\n",
            "Sunday,28-3-2021\n",
            "Sunday,4-4-2021\n",
            "Sunday,11-4-2021\n",
            "Sunday,18-4-2021\n",
            "Sunday,25-4-2021\n",
            "Sunday,2-5-2021\n",
            "Sunday,9-5-2021\n",
            "Sunday,16-5-2021\n",
            "Sunday,23-5-2021\n",
            "Sunday,30-5-2021\n",
            "Sunday,6-6-2021\n",
            "Sunday,13-6-2021\n",
            "Sunday,20-6-2021\n",
            "Sunday,27-6-2021\n",
            "Sunday,4-7-2021\n",
            "Sunday,11-7-2021\n",
            "Sunday,18-7-2021\n",
            "Sunday,25-7-2021\n",
            "Sunday,1-8-2021\n",
            "Sunday,8-8-2021\n",
            "Sunday,15-8-2021\n",
            "Sunday,22-8-2021\n",
            "Sunday,29-8-2021\n",
            "Sunday,5-9-2021\n",
            "Sunday,12-9-2021\n",
            "Sunday,19-9-2021\n",
            "Sunday,26-9-2021\n",
            "Sunday,3-10-2021\n",
            "Sunday,10-10-2021\n",
            "Sunday,17-10-2021\n",
            "Sunday,24-10-2021\n",
            "Sunday,31-10-2021\n",
            "Sunday,7-11-2021\n",
            "Sunday,14-11-2021\n",
            "Sunday,21-11-2021\n",
            "Sunday,28-11-2021\n",
            "Sunday,5-12-2021\n",
            "Sunday,12-12-2021\n",
            "Sunday,19-12-2021\n",
            "Sunday,26-12-2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIpziZ6Sjie-"
      },
      "source": [
        "(3) Python files reading and writing. Download the “[exercise_02_data _collection.zip](https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise_02_data_collection.zip)” to your local and un-zip it.\n",
        "\n",
        "*   Write a program to read all the txt files and save the sentences in all the files into one csv file with two columns, the first column is sentence id (txt file name+sentence line number), the second column is the sentence text content. (4 points)\n",
        "*   Remove all the punctuations from the sentences, save the processed sentences into a new column in the same csv file. (4 points)\n",
        "*   Ask the user to enter a word, return all the sentences that include this word, three kinds of information should be returned: sentence id, sentence text content, the count that user input word appear in the sentence. (4 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4EmF0xs7HuN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "W0HOtukaAKUP",
        "outputId": "daa425c2-68ca-4b73-9637-df768aa98cc6"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "\r\n",
        "# 1)Write a program to read all the txt files and save the sentences in all the files into one CSV file with two columns,\r\n",
        "# the first column is sentence id (txt file name+sentence line number), the second column is the sentence text content.\r\n",
        "\r\n",
        "#all_files = os.listdir(\"/content/\")   # collecting all the file names\r\n",
        "\r\n",
        "all_files=glob.glob(\"./*.txt\")\r\n",
        "\r\n",
        "lines = list()    # a list to collect all the text in all the text files\r\n",
        "for loop1 in range(len(all_files)):\r\n",
        "    with open(\"/content/\" + all_files[loop1]) as f:    # reading the text file\r\n",
        "        lines.append([line.rstrip() for line in f])\r\n",
        "        \r\n",
        "# generating sentence ID\r\n",
        "index = 1\r\n",
        "sent_id = list()\r\n",
        "for text in all_files:\r\n",
        "    for loop2 in range(len(lines)+1):\r\n",
        "        sent_id.append(text.split('.')[0]+'_'+str(index))  # appending file name and sentence number\r\n",
        "        index += 1\r\n",
        "\r\n",
        "# creating a dataframe of the text data\r\n",
        "text_data_df = pd.DataFrame()\r\n",
        "text_data_df['sent_id'] = sent_id\r\n",
        "text_data_df[\"txt\"] = [text for item in lines for text in item]\r\n",
        "text_data_df.to_csv('text_data_df.csv', index=False)    # saving the csv file to the disk\r\n",
        "text_data_df\r\n",
        "\r\n",
        "\r\n",
        "# 2)Remove all the punctuations from the sentences, save the processed sentences into a new column in the same CSV file\r\n",
        "\r\n",
        "# removing everything except characters and number\r\n",
        "new_text = [[re.sub(r'[^a-zA-Z0-9 ]+', '', word) for word in text_data_df['text']]]\r\n",
        "new_text = [text for item in new_text for text in item]\r\n",
        "text_data_df['new_text'] = new_text\r\n",
        "text_data_df.to_csv('text_data_df.csv', index=False)    # saving the csv file to the disk\r\n",
        "text_data_df\r\n",
        "\r\n",
        "\r\n",
        "# 3)Ask the user to enter a word, return all the sentences that include this word, three kinds of information should be\r\n",
        "# returned: sentence id, sentence text content, the count that user input word appears in the sentence.\r\n",
        "\r\n",
        "word = input('Please enter a word: ')\r\n",
        "\r\n",
        "index = list()     # list to store sentence number if the word exists\r\n",
        "all_count = list()  # list of occurance of a word\r\n",
        "for loop1 in range(len(text_data_df)):\r\n",
        "    tokens = text_data_df['new_text'][loop1].split()  # tokens of current sentence\r\n",
        "    count = 0     # count of occurance of a word\r\n",
        "    for loop2 in range(len(tokens)):\r\n",
        "        if(word == tokens[loop2]):\r\n",
        "            index.append(loop1)\r\n",
        "            count += 1\r\n",
        "    if(count > 0):\r\n",
        "        all_count.append(count)\r\n",
        "    \r\n",
        "index = sorted(list(set(index)))\r\n",
        "\r\n",
        "# printint output\r\n",
        "output = text_data_df.iloc[index]\r\n",
        "output['count'] = all_count\r\n",
        "output\r\n",
        "\r\n"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-305-9cc2711d5252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtext_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtext_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtext_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"txt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mtext_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_data_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# saving the csv file to the disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtext_data_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (1605) does not match length of index (90300)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQNI4GDL_bBt",
        "outputId": "3426bac6-06fd-4236-d625-65825892ab10"
      },
      "source": [
        ""
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<built-in function listdir>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXh-bqaO7J0Q"
      },
      "source": [
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-12cqmJEpZOh"
      },
      "source": [
        "(4) Install packages nltk, numpy, scipy, pandas, and sklearn on Google Colab. Write a program to test whether they are installed successfully. (3 points for extra)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1pn1Zl2qK77"
      },
      "source": [
        "# write your answer here\n",
        "\n",
        "! pip install nltk\n",
        "! pip install numpy\n",
        "! pip install scipy\n",
        "! pip install pandas\n",
        "! pip install scikit-learn\n",
        "\n",
        "\n",
        "# testing the nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()\n",
        "text = \"God is Great! I won a lottery.\"\n",
        "print(tknzr.tokenize(text))\n",
        "\n",
        "\n",
        "#Testing numpy \n",
        "\n",
        "import numpy as np\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(arr)\n",
        "\n",
        "#Testing scipy\n",
        "from scipy import constants\n",
        "print(constants.litre)\n",
        "\n",
        "\n",
        "\n",
        "#Testing panddas\n",
        "print('testing pandas')\n",
        "import pandas as pd\n",
        "\n",
        "mylist = [4, 8, 12, 16, 20]\n",
        "df = pd.DataFrame(mylist)\n",
        "print(df)\n",
        "\n",
        "print('Testing Pandas completed #####################################################')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "print(\"Target names:\", target_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}